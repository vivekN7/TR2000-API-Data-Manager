# Migration Plan - RAW_JSON Architecture Fix

## Overview

This document provides the step-by-step implementation plan to fix the RAW_JSON architecture and achieve industry-standard API → RAW_JSON → STG → CORE data flow.

## Current Status (Session 27)

### ✅ **What's Working:**
- Smart Workflow: 98.5% API call reduction operational
- LoadOperators, LoadPlants, LoadIssues: All working perfectly
- Date Parsing: European formats handled with PARSE_TR2000_DATE()
- SCD2 Processing: Complete temporal tracking working
- Application: Production ready at http://localhost:5005/etl-operations

### ❌ **What's Broken:**
- RAW_JSON architecture: Parameter mismatch causing complete bypass
- Audit trail: No record of actual API responses
- Replay capability: Missing due to empty RAW_JSON table
- Industry compliance: Violating standard ETL patterns

## Implementation Plan

### **Session 28: Oracle DDL & C# Fixes (Phase 1)**

#### **Step 1: Update RAW_JSON Table Structure**
```sql
-- Backup existing table (if needed)
CREATE TABLE RAW_JSON_BACKUP AS SELECT * FROM RAW_JSON;

-- Drop and recreate with enhanced structure
DROP TABLE RAW_JSON;

CREATE TABLE RAW_JSON (
  JSON_ID            NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  ETL_RUN_ID         NUMBER,
  ENDPOINT_NAME      VARCHAR2(100) NOT NULL,
  REQUEST_URL        VARCHAR2(1000),
  REQUEST_PARAMS     CLOB,
  RESPONSE_STATUS    NUMBER,
  PLANT_ID           VARCHAR2(50),
  CREATED_DATE       TIMESTAMP(6) DEFAULT SYSTIMESTAMP NOT NULL,
  JSON_DATA          CLOB CHECK (JSON_DATA IS JSON),
  RESP_HASH_SHA256   RAW(32) NOT NULL,
  PROCESSED_FLAG     CHAR(1) DEFAULT 'N' CHECK (PROCESSED_FLAG IN ('Y','N'))
);

CREATE INDEX IX_RAWJSON_PICK
  ON RAW_JSON (ENDPOINT_NAME, PROCESSED_FLAG, CREATED_DATE);
```

#### **Step 2: Update SP_INSERT_RAW_JSON Procedure**
```sql
CREATE OR REPLACE PROCEDURE SP_INSERT_RAW_JSON(
    p_etl_run_id     NUMBER,
    p_endpoint       VARCHAR2,
    p_request_url    VARCHAR2 DEFAULT NULL,
    p_request_params CLOB DEFAULT NULL,
    p_response_status NUMBER DEFAULT 200,
    p_plant_id       VARCHAR2 DEFAULT NULL,
    p_json_data      CLOB,
    p_duration_ms    NUMBER DEFAULT NULL,
    p_headers        CLOB DEFAULT NULL
) AS
    v_hash RAW(32);
BEGIN
    -- Compute hash for deduplication
    v_hash := STANDARD_HASH(p_json_data, 'SHA256');
    
    -- Insert with comprehensive metadata
    INSERT INTO RAW_JSON (
        ETL_RUN_ID, ENDPOINT_NAME, REQUEST_URL, REQUEST_PARAMS,
        RESPONSE_STATUS, PLANT_ID, JSON_DATA, RESP_HASH_SHA256
    ) VALUES (
        p_etl_run_id, p_endpoint, p_request_url, p_request_params,
        p_response_status, p_plant_id, p_json_data, v_hash
    );
    
EXCEPTION
    WHEN OTHERS THEN
        -- Log error but don't break ETL
        LOG_ETL_ERROR(p_etl_run_id, 'RAW_JSON_INSERT', 'SP_INSERT_RAW_JSON', SQLERRM);
END SP_INSERT_RAW_JSON;
/
```

#### **Step 3: Update C# InsertRawJson Method**
**File**: `/TR2KBlazorLibrary/Logic/Services/OracleETLServiceV2.cs`

```csharp
private async Task InsertRawJson(
    OracleConnection connection, 
    int etlRunId, 
    string endpoint, 
    string keyString,
    string apiResponse,
    int httpStatus = 200,
    int? durationMs = null)
{
    try
    {
        await connection.ExecuteAsync(@"
            BEGIN
                SP_INSERT_RAW_JSON(
                    p_etl_run_id     => :etlRunId,
                    p_endpoint       => :endpoint,
                    p_request_url    => :requestUrl,
                    p_request_params => :requestParams,
                    p_response_status => :httpStatus,
                    p_plant_id       => :plantId,
                    p_json_data      => :jsonData,
                    p_duration_ms    => :durationMs,
                    p_headers        => :headers
                );
            END;",
            new 
            { 
                etlRunId,
                endpoint,
                requestUrl = $"https://equinor.pipespec-api.presight.com/{endpoint}",
                requestParams = (string)null, // Can be enhanced later
                httpStatus,
                plantId = ExtractPlantIdFromKey(keyString), // Helper method
                jsonData = apiResponse,
                durationMs,
                headers = "{\"Content-Type\": \"application/json\"}"
            });
        
        _logger.LogDebug($"RAW_JSON inserted for {endpoint}");
    }
    catch (Exception ex)
    {
        // Log error but don't break ETL
        _logger.LogWarning($"RAW_JSON insert failed: {ex.Message}");
    }
}
```

#### **Step 4: Test RAW_JSON Insertion**
1. Run LoadOperators and verify RAW_JSON table populated
2. Check no more "RAW_JSON insert failed" warnings
3. Validate metadata captured correctly

### **Session 29: JSON Parsing & ETL Flow (Phase 2)**

#### **Step 1: Create JSON_TABLE Parsing Procedures**

**For OPERATORS:**
```sql
CREATE OR REPLACE PROCEDURE SP_PARSE_OPERATORS_FROM_RAW_JSON AS
BEGIN
    INSERT INTO STG_OPERATORS (RAW_JSON_ID, ETL_RUN_ID, OPERATOR_ID, OPERATOR_NAME)
    SELECT 
        r.JSON_ID,
        r.ETL_RUN_ID,
        TO_NUMBER(jt.operator_id),
        jt.operator_name
    FROM RAW_JSON r
    CROSS APPLY JSON_TABLE(
        r.JSON_DATA,
        '$[*]'
        COLUMNS (
            operator_id   VARCHAR2(50)  PATH '$.OperatorID',
            operator_name VARCHAR2(200) PATH '$.OperatorName'
        )
    ) jt
    WHERE r.ENDPOINT_NAME = 'operators'
      AND r.PROCESSED_FLAG = 'N';
    
    -- Mark as processed
    UPDATE RAW_JSON 
       SET PROCESSED_FLAG = 'Y'
     WHERE ENDPOINT_NAME = 'operators'
       AND PROCESSED_FLAG = 'N';
END;
/
```

**For PLANTS:**
```sql
CREATE OR REPLACE PROCEDURE SP_PARSE_PLANTS_FROM_RAW_JSON AS
BEGIN
    INSERT INTO STG_PLANTS (RAW_JSON_ID, ETL_RUN_ID, PLANT_ID, SHORT_DESCRIPTION, ...)
    SELECT 
        r.JSON_ID,
        r.ETL_RUN_ID,
        jt.*
    FROM RAW_JSON r
    CROSS APPLY JSON_TABLE(
        r.JSON_DATA,
        '$[*]'
        COLUMNS (
            plant_id          VARCHAR2(50)  PATH '$.PlantID',
            short_description VARCHAR2(200) PATH '$.ShortDescription',
            -- Add all 24+ PLANTS fields
            ...
        )
    ) jt
    WHERE r.ENDPOINT_NAME = 'plants'
      AND r.PROCESSED_FLAG = 'N';
    
    UPDATE RAW_JSON 
       SET PROCESSED_FLAG = 'Y'
     WHERE ENDPOINT_NAME = 'plants'
       AND PROCESSED_FLAG = 'N';
END;
/
```

#### **Step 2: Update Master Orchestrator**
```sql
-- Update SP_PROCESS_ETL_BATCH to parse from RAW_JSON first
CREATE OR REPLACE PROCEDURE SP_PROCESS_ETL_BATCH(
    p_entity_type VARCHAR2,
    p_etl_run_id NUMBER
) AS
BEGIN
    -- Step 1: Parse RAW_JSON to STG_TABLES
    IF p_entity_type = 'OPERATORS' THEN
        SP_PARSE_OPERATORS_FROM_RAW_JSON;
    ELSIF p_entity_type = 'PLANTS' THEN  
        SP_PARSE_PLANTS_FROM_RAW_JSON;
    ELSIF p_entity_type = 'ISSUES' THEN
        SP_PARSE_ISSUES_FROM_RAW_JSON;
    END IF;
    
    -- Step 2: Existing processing (unchanged)
    SP_DEDUPLICATE_STAGING(p_etl_run_id, p_entity_type);
    -- ... rest of existing logic
    
    COMMIT;
END;
/
```

#### **Step 3: Update C# ETL Flow**
**Modify LoadOperators, LoadPlants, LoadIssues to:**
1. Insert to RAW_JSON (already done in Phase 1)
2. Call orchestrator to parse RAW_JSON → STG → DIM
3. Remove direct STG table insertion

### **Session 30: Testing & Validation (Phase 3)**

#### **Step 1: End-to-End Testing**
1. Test complete flow: API → RAW_JSON → STG → DIM
2. Verify Smart Workflow performance maintained
3. Test all entity types (Operators, Plants, Issues, References)

#### **Step 2: Audit Trail Validation**
1. Verify RAW_JSON contains all API responses
2. Test lineage tracking from DIM back to RAW_JSON
3. Validate metadata accuracy

#### **Step 3: Replay Functionality**
```sql
-- Test replay capability
CREATE OR REPLACE PROCEDURE SP_REPLAY_FROM_RAW_JSON(
    p_start_date DATE,
    p_end_date   DATE,
    p_endpoint   VARCHAR2 DEFAULT NULL
) AS
BEGIN
    -- Reset processed flags
    UPDATE RAW_JSON
       SET PROCESSED_FLAG = 'N'
     WHERE CREATED_DATE BETWEEN p_start_date AND p_end_date
       AND (p_endpoint IS NULL OR ENDPOINT_NAME = p_endpoint);
    
    -- Re-trigger processing
    SP_PROCESS_ETL_BATCH('REPLAY', 0);
END;
/
```

## Success Criteria

### **Phase 1 Success Metrics:**
- ✅ RAW_JSON table receives all API responses
- ✅ No "RAW_JSON insert failed" warnings
- ✅ Comprehensive metadata captured (URL, status, duration, etc.)
- ✅ Hash-based deduplication working

### **Phase 2 Success Metrics:**
- ✅ STG_TABLES populated from RAW_JSON (not direct API)
- ✅ JSON_TABLE parsing working correctly
- ✅ Processed flags managed properly
- ✅ Existing SCD2 processing unchanged

### **Phase 3 Success Metrics:**
- ✅ Complete audit trail operational
- ✅ Replay functionality working
- ✅ Smart Workflow performance maintained (98.5% API reduction)
- ✅ Industry standard architecture achieved
- ✅ All lineage tracking functional

## Rollback Plan

### **If Issues Encountered:**
1. **Phase 1 Rollback**: Restore old SP_INSERT_RAW_JSON, continue with existing flow
2. **Phase 2 Rollback**: Disable JSON_TABLE parsing, use direct STG insertion
3. **Phase 3 Rollback**: Revert to previous orchestrator version

### **Emergency Fallback:**
- Core ETL (STG → DIM) remains unchanged throughout
- Smart Workflow preserved in all phases
- Can always fall back to direct API → STG flow

## Dependencies

### **None - This is Additive:**
- Core ETL functionality working
- Smart Workflow operational  
- Date parsing resolved
- All user-facing features working

### **No Breaking Changes:**
- Existing SCD2 processing unchanged
- Performance characteristics maintained
- User interface unchanged
- API call reduction preserved

## Resource Requirements

### **Development Time:**
- **Session 28**: 2-3 hours (Oracle DDL + C# fixes)
- **Session 29**: 2-3 hours (JSON parsing + ETL flow)
- **Session 30**: 1-2 hours (testing + validation)

### **Testing Environment:**
- Existing Oracle database
- Existing application
- No additional infrastructure required

---
**Document Status**: Implementation Ready
**Next Session**: Session 28 - Begin Phase 1 implementation
**Risk Level**: Low (additive changes only, core ETL preserved)